{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import math\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataEncoder:\n",
    "    def __init__(self):\n",
    "        '''Compute default box sizes with scale and aspect transform.'''\n",
    "        scale = 300.\n",
    "        steps = [s / scale for s in (8, 16, 32, 64, 100, 300)]\n",
    "        sizes = [s / scale for s in (30, 60, 111, 162, 213, 264, 315)]\n",
    "        aspect_ratios = ((2,), (2,3), (2,3), (2,3), (2,), (2,))\n",
    "        feature_map_sizes = (38, 19, 10, 5, 3, 1)\n",
    "        # 38×38×4+19×19×6+10×10×6+5×5×6+3×3×4+1×1×4=8732\n",
    "        num_layers = len(feature_map_sizes)\n",
    "\n",
    "        boxes = []\n",
    "        for i in range(num_layers):\n",
    "            fmsize = feature_map_sizes[i] # feature map size \n",
    "            for h,w in itertools.product(range(fmsize), repeat=2):\n",
    "                cx = (w + 0.5)*steps[i]\n",
    "                cy = (h + 0.5)*steps[i]\n",
    "\n",
    "                s = sizes[i]\n",
    "                boxes.append((cx, cy, s, s))\n",
    "\n",
    "                s = math.sqrt(sizes[i] * sizes[i+1])\n",
    "                boxes.append((cx, cy, s, s))\n",
    "\n",
    "                s = sizes[i]\n",
    "                for ar in aspect_ratios[i]:\n",
    "                    boxes.append((cx, cy, s * math.sqrt(ar), s / math.sqrt(ar)))\n",
    "                    boxes.append((cx, cy, s / math.sqrt(ar), s * math.sqrt(ar)))\n",
    "\n",
    "        self.default_boxes = torch.Tensor(boxes)\n",
    "\n",
    "    def iou(self, box1, box2):\n",
    "        '''Compute the intersection over union of two set of boxes, each box is [x1,y1,x2,y2].\n",
    "        Args:\n",
    "          box1: (tensor) bounding boxes, sized [N,4].\n",
    "          box2: (tensor) bounding boxes, sized [M,4].\n",
    "        Return:\n",
    "          (tensor) iou, sized [N,M].\n",
    "        '''\n",
    "        N = box1.size(0)\n",
    "        M = box2.size(0)\n",
    "\n",
    "        lt = torch.max(\n",
    "            box1[:,:2].unsqueeze(1).expand(N,M,2),  # [N,2] -> [N,1,2] -> [N,M,2]\n",
    "            box2[:,:2].unsqueeze(0).expand(N,M,2),  # [M,2] -> [1,M,2] -> [N,M,2]\n",
    "        )\n",
    "\n",
    "        rb = torch.min(\n",
    "            box1[:,2:].unsqueeze(1).expand(N,M,2),  # [N,2] -> [N,1,2] -> [N,M,2]\n",
    "            box2[:,2:].unsqueeze(0).expand(N,M,2),  # [M,2] -> [1,M,2] -> [N,M,2]\n",
    "        )\n",
    "\n",
    "        wh = rb - lt  # [N,M,2]\n",
    "        wh[wh<0] = 0  # clip at 0\n",
    "        inter = wh[:,:,0] * wh[:,:,1]  # [N,M]\n",
    "\n",
    "        area1 = (box1[:,2]-box1[:,0]) * (box1[:,3]-box1[:,1])  # [N,]\n",
    "        area2 = (box2[:,2]-box2[:,0]) * (box2[:,3]-box2[:,1])  # [M,]\n",
    "        area1 = area1.unsqueeze(1).expand_as(inter)  # [N,] -> [N,1] -> [N,M]\n",
    "        area2 = area2.unsqueeze(0).expand_as(inter)  # [M,] -> [1,M] -> [N,M]\n",
    "\n",
    "        iou = inter / (area1 + area2 - inter)\n",
    "        return iou\n",
    "\n",
    "    def encode(self, boxes, classes, threshold=0.5):\n",
    "        '''Transform target bounding boxes and class labels to SSD boxes and classes.\n",
    "        Match each object box to all the default boxes, pick the ones with the\n",
    "        Jaccard-Index > 0.5:\n",
    "            Jaccard(A,B) = AB / (A+B-AB)\n",
    "        Args:\n",
    "          boxes: (tensor) object bounding boxes (xmin,ymin,xmax,ymax) of a image, sized [#obj, 4].\n",
    "          classes: (tensor) object class labels of a image, sized [#obj,].\n",
    "          threshold: (float) Jaccard index threshold\n",
    "        Returns:\n",
    "          boxes: (tensor) bounding boxes, sized [#obj, 8732, 4].\n",
    "          classes: (tensor) class labels, sized [8732,]\n",
    "        '''\n",
    "        default_boxes = self.default_boxes\n",
    "        num_default_boxes = default_boxes.size(0)\n",
    "        num_objs = boxes.size(0)\n",
    "\n",
    "        iou = self.iou(  # [#obj,8732]\n",
    "            boxes,\n",
    "            torch.cat([default_boxes[:,:2] - default_boxes[:,2:]/2,\n",
    "                       default_boxes[:,:2] + default_boxes[:,2:]/2], 1)\n",
    "        )\n",
    "\n",
    "        iou, max_idx = iou.max(0)  # [1,8732]\n",
    "        max_idx.squeeze_(0)        # [8732,]\n",
    "        iou.squeeze_(0)            # [8732,]\n",
    "\n",
    "        boxes = boxes[max_idx]     # [8732,4]\n",
    "        variances = [0.1, 0.2]\n",
    "        cxcy = (boxes[:,:2] + boxes[:,2:])/2 - default_boxes[:,:2]  # [8732,2]\n",
    "        cxcy /= variances[0] * default_boxes[:,2:]\n",
    "        wh = (boxes[:,2:] - boxes[:,:2]) / default_boxes[:,2:]      # [8732,2]\n",
    "        wh = torch.log(wh) / variances[1]\n",
    "        loc = torch.cat([cxcy, wh], 1)  # [8732,4]\n",
    "\n",
    "        conf = 1 + classes[max_idx]   # [8732,], background class = 0\n",
    "        conf[iou<threshold] = 0       # background\n",
    "        return loc, conf\n",
    "\n",
    "    def nms(self, bboxes, scores, threshold=0.3, mode='union'):\n",
    "        '''Non maximum suppression.\n",
    "        Args:\n",
    "          bboxes: (tensor) bounding boxes, sized [N,4].\n",
    "          scores: (tensor) bbox scores, sized [N,].\n",
    "          threshold: (float) overlap threshold.\n",
    "          mode: (str) 'union' or 'min'.\n",
    "        Returns:\n",
    "          keep: (tensor) selected indices.\n",
    "        Ref:\n",
    "          https://github.com/rbgirshick/py-faster-rcnn/blob/master/lib/nms/py_cpu_nms.py\n",
    "        '''\n",
    "        x1 = bboxes[:,0]\n",
    "        y1 = bboxes[:,1]\n",
    "        x2 = bboxes[:,2]\n",
    "        y2 = bboxes[:,3]\n",
    "\n",
    "        areas = (x2-x1) * (y2-y1)\n",
    "        _, order = scores.sort(0, descending=True)\n",
    "\n",
    "        keep = []\n",
    "        while order.numel() > 0: \n",
    "            i = order[0]\n",
    "            keep.append(i)\n",
    "\n",
    "            if order.numel() == 1:\n",
    "                break\n",
    "\n",
    "            xx1 = x1[order[1:]].clamp(min=x1[i])\n",
    "            yy1 = y1[order[1:]].clamp(min=y1[i])\n",
    "            xx2 = x2[order[1:]].clamp(max=x2[i])\n",
    "            yy2 = y2[order[1:]].clamp(max=y2[i])\n",
    "\n",
    "            w = (xx2-xx1).clamp(min=0)\n",
    "            h = (yy2-yy1).clamp(min=0)\n",
    "            inter = w*h\n",
    "\n",
    "            if mode == 'union':\n",
    "                ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "            elif mode == 'min':\n",
    "                ovr = inter / areas[order[1:]].clamp(max=areas[i])\n",
    "            else:\n",
    "                raise TypeError('Unknown nms mode: %s.' % mode)\n",
    "\n",
    "            ids = (ovr<=threshold).nonzero().squeeze()\n",
    "            if ids.numel() == 0:\n",
    "                break\n",
    "            order = order[ids+1]\n",
    "        return torch.LongTensor(keep)\n",
    "\n",
    "    def decode(self, loc, conf):\n",
    "        '''Transform predicted loc/conf back to real bbox locations and class labels.\n",
    "        Args:\n",
    "          loc: (tensor) predicted loc, sized [8732,4].\n",
    "          conf: (tensor) predicted conf, sized [8732,21].\n",
    "        Returns:\n",
    "          boxes: (tensor) bbox locations, sized [#obj, 4].\n",
    "          labels: (tensor) class labels, sized [#obj,1].\n",
    "        '''\n",
    "        variances = (0.1, 0.2)\n",
    "        wh = torch.exp(loc[:,2:]*variances[1]) * self.default_boxes[:,2:]\n",
    "        cxcy = loc[:,:2] * variances[0] * self.default_boxes[:,2:] + self.default_boxes[:,:2]\n",
    "        box_preds = torch.cat([cxcy-wh/2, cxcy+wh/2], 1)  # [8732,4]\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        scores = []\n",
    "        num_classes = conf.size(1)\n",
    "        for i in range(num_classes-1):\n",
    "            score = conf[:,i+1]  # class i corresponds to (i+1) column\n",
    "            mask = score > 0.1\n",
    "            \n",
    "            if not mask.any():\n",
    "                continue\n",
    "           \n",
    "            box = box_preds[mask.nonzero().squeeze()]\n",
    "            score = score[mask]\n",
    "            \n",
    "            if len(score) == 1:\n",
    "                continue\n",
    "            keep = self.nms(box, score, threshold=0.3)\n",
    "            boxes.append(box[keep])\n",
    "            labels.append(torch.LongTensor(len(box[keep])).fill_(i))\n",
    "            scores.append(score[keep])\n",
    "\n",
    "        return boxes, labels, scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_dir",
   "language": "python",
   "name": "env_dir"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
